name: Daily Energy Data Sync

on:
  schedule:
    # Run daily at 2 AM UTC (9 PM EST / 8 PM EDT)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: read   # Required for actions/checkout to clone the repo
  issues: write

jobs:
  sync-data:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/python_scripts/requirements.txt

      - name: Install backend package
        run: pip install -e backend/python_scripts/

      - name: Discover active sites
        id: sites
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          SITES_JSON=$(python backend/python_scripts/operations/list_active_sites.py --json)
          echo "sites_json<<EOF" >> "$GITHUB_OUTPUT"
          echo "$SITES_JSON" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "Discovered active sites (from sites table):"
          echo "$SITES_JSON" | jq -r '.[] | "  \(.site_name) (id=\(.site_id)) wcds_only=\(.wcds_only) resolution=\(.resolution)"'

      - name: Run ingestion for each site
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          ENISCOPE_API_KEY: ${{ secrets.ENISCOPE_API_KEY }}
          ENISCOPE_EMAIL: ${{ secrets.ENISCOPE_EMAIL }}
          ENISCOPE_PASSWORD: ${{ secrets.ENISCOPE_PASSWORD }}
          ENISCOPE_API_URL: https://core.eniscope.com
          SITES_JSON: ${{ steps.sites.outputs.sites_json }}
        run: |
          FAILED=0
          mapfile -t sites < <(echo "$SITES_JSON" | jq -c '.[]')
          for site in "${sites[@]}"; do
            SITE_ID=$(echo "$site" | jq -r '.site_id')
            WCDS=$(echo "$site" | jq -r '.wcds_only // false')
            RES=$(echo "$site" | jq -r '.resolution // 3600')
            WCDS_FLAG=""
            [ "$WCDS" = "true" ] && WCDS_FLAG="--wcds-only"
            echo ""
            echo "=== Syncing site $SITE_ID (resolution=${RES}s, wcds_only=${WCDS}) ==="
            python backend/python_scripts/ingest/ingest_to_postgres.py \
              --site "$SITE_ID" --days 3 $WCDS_FLAG --resolution "$RES" \
            || { echo "Site $SITE_ID FAILED"; FAILED=1; }
          done
          if [ $FAILED -ne 0 ]; then exit 1; fi

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const runUrl = `${context.payload.repository.html_url}/actions/runs/${context.runId}`;
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Daily Sync Failed â€” ${new Date().toISOString().slice(0,10)}`,
              body: `The daily energy data sync workflow failed.\n\n**Run:** [View logs](${runUrl})\n**Time:** ${new Date().toISOString()}\n\nPlease check the workflow logs for details and re-run manually if needed.`,
              labels: ['pipeline-failure', 'automated']
            })
